Chapter 3: Converged in Action â€“ Industry Playbooks for Oracle 23ai

â€œArchitecture is only theory until it meets the battlefield of business.â€
This chapter is now restructured into six detailed, standalone playbooks â€” each designed as a workshop-ready lab paper tailored to a specific industry. These are not just success stories; they are roadmaps for replicable transformation using Oracle 23ai.

Each lab has been further expanded as a guided technical do-along â€” designed to help implement real-world use cases with converged features step by step, while maintaining architectural integrity.

3.1 Financial Services â€“ From Risk to Real-Time Revenue
Lab Objective: Modernize financial architectures with fraud detection, compliance, and real-time analytics using Oracle 23ai.

Key Challenges:

Regulatory compliance across jurisdictions
Real-time fraud detection
Fragmented systems and legacy modernization
Oracle 23ai Solutions:

Graph + AutoML for entity resolution and fraud pattern detection
JSON Duality Views to model applications and onboarding forms
In-DB Analytics to ensure traceable portfolio performance
Data Sovereignty: Stay compliant by minimizing egress to third-party tools
ðŸ§ª Guided Tech Do-Along

Lab Duration: ~3 Hours

Prerequisites:

Oracle Database 23ai (Local VM or Oracle Cloud)
Oracle APEX (Developer mode)
Oracle Machine Learning (OML) enabled
Sample data files provided via GitHub or classroom
SQL Developer or OCI Cloud Shell
Step-by-Step Walkthrough:

Step 1: Setup Environment

Launch Oracle 23ai instance from OCI Marketplace or local Docker
Use SQL Developer to connect and run:
CREATE USER banklab IDENTIFIED BY Welcome1;
GRANT DBA TO banklab;
ALTER SESSION SET CURRENT_SCHEMA = banklab;
Step 2: Schema Creation

CREATE TABLE customer (
  cust_id NUMBER PRIMARY KEY,
  name VARCHAR2(100),
  dob DATE,
  kyc JSON);

CREATE TABLE account (
  acct_id NUMBER PRIMARY KEY,
  cust_id NUMBER,
  acct_type VARCHAR2(20),
  balance NUMBER,
  FOREIGN KEY (cust_id) REFERENCES customer(cust_id));

CREATE TABLE device (
  device_id VARCHAR2(50) PRIMARY KEY,
  cust_id NUMBER,
  ip_address VARCHAR2(45));

CREATE TABLE transaction (
  txn_id NUMBER PRIMARY KEY,
  acct_id NUMBER,
  txn_time TIMESTAMP,
  amount NUMBER,
  channel VARCHAR2(20),
  device_id VARCHAR2(50),
  fraud_flag NUMBER);
Step 3: Load Data

Download CSV files from the lab repo.
Use SQL Developer or SQL*Loader:
-- Sample insert
INSERT INTO customer VALUES (1001, 'Amit Shah', TO_DATE('1980-10-12','YYYY-MM-DD'), '{"aadhaar":"XXXX"}');
Step 4: Graph Creation

CREATE PROPERTY GRAPH financial_pg
  VERTEX TABLES (
    customer KEY (cust_id),
    account KEY (acct_id),
    device KEY (device_id))
  EDGE TABLES (
    owns FROM customer TO account,
    accessed_by FROM account TO device);
Run Graph queries like:

SELECT * FROM PGQL_QUERY('financial_pg', 'MATCH (c:customer)-[:owns]->(a:account)-[:accessed_by]->(d:device) RETURN c, a, d');
Step 5: Fraud Detection with AutoML

BEGIN
  DBMS_DATA_MINING.CREATE_MODEL(
    model_name          => 'FRAUD_MODEL',
    mining_function     => DBMS_DATA_MINING.CLASSIFICATION,
    data_table_name     => 'transaction',
    case_id_column_name => 'txn_id',
    target_column_name  => 'fraud_flag',
    settings_table_name => 'fraud_settings');
END;
Step 6: Create APEX Dashboard

Login to APEX Workspace â†’ Create App â†’ Add Charts â†’ Use SQL Query with fraud flags.
Add filters for amount, device_id, txn_time.
Expected Outcomes:

Understand graph modeling and query basics
Deploy a predictive model without external ML tools
Build simple data-to-insight workflow in APEX
Launch an intelligent fraud monitoring prototype in under 3 hours
â€œAs a DBA, this was my first time using Graph and AutoML inside Oracle itself. I didnâ€™t expect I could do ML without Python or Jupyter.â€ â€“ Beta Tester from Banking Partner


3.2 Retail & E-Commerce â€“ Real-Time Personalization, Zero ETL
Lab Objective: Deliver hyper-personalized shopping and reduce ETL through native intelligence in Oracle 23ai.

Key Challenges:

Semantic product discovery
Inventory intelligence across channels
High ETL overhead and delay in campaign rollout
Oracle 23ai Solutions:

Vector Search for similarity-based product discovery
Graph for User Behavior: capture clicks, views, carts as relationships
AutoML for predicting churn, conversion, inventory anomalies
ðŸ§ª Guided Tech Do-Along

Lab Duration: ~3.5 Hours

Prerequisites:

Oracle 23ai (with Vector Search enabled)
JSON and APEX features active
Sample catalog with images and embeddings
Step-by-Step Walkthrough:

Step 1: JSON Catalog Setup

CREATE TABLE product_catalog (
  id NUMBER PRIMARY KEY,
  metadata JSON,
  embedding VECTOR(1536));
Insert products with categories, tags, image URLs
Use Oracle Vector API or external embedding source to populate vector column
Step 2: Load Behavior Data

CREATE TABLE user_behavior (
  user_id NUMBER,
  product_id NUMBER,
  action VARCHAR2(20),
  event_time TIMESTAMP);
Step 3: Graph Generation

CREATE PROPERTY GRAPH retail_pg
  VERTEX TABLES (product_catalog KEY (id))
  EDGE TABLES (clicked FROM user_behavior TO product_catalog);
Step 4: Churn Prediction Model

Create user_profiles table with recency, frequency, monetary metrics
Build and test model in-database using AutoML
Step 5: Build Recommender REST + APEX

SQL query:
SELECT * FROM product_catalog
WHERE embedding ANN [customer_vector] LIMIT 5;
Link response to an APEX â€œRecommended For Youâ€ dashboard card
Expected Outcomes:

Gain comfort with JSON + Vector data in one schema
Understand how user behavior data maps to graph
Build low-latency recommendations without separate ML infra
Launch real-time, no-ETL personalized shopping app in 3.5 hrs



3.3 Healthcare â€“ Building a Patient 360 & Predictive Diagnostics Lab
Lab Objective: Create a unified patient 360 view and predictive diagnostics model using Oracle 23ai, while strictly enforcing healthcare compliance and data privacy.

Key Challenges:

Fragmented patient data from multiple sources
Integration of semi-structured clinical notes, genomic data, and imaging metadata
Regulatory compliance for privacy and data protection (HIPAA, GDPR)
Oracle 23ai Solutions:

JSON Duality Views for managing structured and unstructured clinical data
Graph DB for patient-provider relationships and care pathways
Vector Search for imaging and genomic sequence similarity
AutoML for predictive risk scoring and diagnosis assistance
Data Security: Transparent Data Encryption (TDE), Virtual Private Database (VPD), and audit logging for compliance
ðŸ§ª Guided Tech Do-Along

Lab Duration: ~3.5 Hours

Prerequisites:

Oracle Database 23ai with JSON, Graph, Vector, AutoML enabled
Oracle APEX workspace for dashboarding
Sample anonymized healthcare datasets (patients, clinical notes, images metadata)
SQL Developer or OCI Cloud Shell
Step 1: Setup User and Schema

CREATE USER healthlab IDENTIFIED BY Health123;
GRANT CONNECT, RESOURCE, CREATE VIEW TO healthlab;
ALTER SESSION SET CURRENT_SCHEMA = healthlab;
Step 2: Create Core Tables Using JSON Duality

CREATE TABLE patient (
  patient_id NUMBER PRIMARY KEY,
  name VARCHAR2(100),
  dob DATE,
  demographics JSON
);

CREATE TABLE clinical_notes (
  note_id NUMBER PRIMARY KEY,
  patient_id NUMBER,
  note_content CLOB,
  metadata JSON,
  CONSTRAINT fk_patient FOREIGN KEY (patient_id) REFERENCES patient(patient_id)
);

CREATE TABLE imaging_data (
  image_id NUMBER PRIMARY KEY,
  patient_id NUMBER,
  image_metadata JSON,
  embedding VECTOR(1536),
  CONSTRAINT fk_patient_img FOREIGN KEY (patient_id) REFERENCES patient(patient_id)
);
Step 3: Load Anonymized Data

Download anonymized patient records, clinical notes, and imaging metadata from provided repo.
Use SQL Developer or SQL*Loader to bulk insert JSON and vector data.
Step 4: Create Property Graph to Model Care Relationships

CREATE PROPERTY GRAPH healthcare_pg
  VERTEX TABLES (
    patient KEY (patient_id),
    clinical_notes KEY (note_id),
    imaging_data KEY (image_id)
  )
  EDGE TABLES (
    has_note FROM patient TO clinical_notes,
    has_image FROM patient TO imaging_data
  );
Run sample queries:

SELECT * FROM PGQL_QUERY('healthcare_pg', 
  'MATCH (p:patient)-[:has_note]->(n:clinical_notes) WHERE p.patient_id = 101 RETURN p, n');
Step 5: Vector Search on Imaging Data

SELECT image_id, image_metadata
FROM imaging_data
WHERE embedding ANN VECTOR_OF_INTEREST LIMIT 5;
Use embeddings for similarity search to find related patient images for diagnostics.

Step 6: Build AutoML Predictive Model for Readmission Risk

Prepare training data combining JSON attributes and vector features, then:

BEGIN
  DBMS_DATA_MINING.CREATE_MODEL(
    model_name          => 'PATIENT_READMISSION_MODEL',
    mining_function     => DBMS_DATA_MINING.CLASSIFICATION,
    data_table_name     => 'patient_risk_data',
    case_id_column_name => 'patient_id',
    target_column_name  => 'readmission_flag',
    settings_table_name => 'health_settings');
END;
Step 7: Implement Security and Compliance Controls

Enable Transparent Data Encryption (TDE) on healthcare tables.
Create Virtual Private Database (VPD) policies to restrict row access based on user roles.
Configure audit logging on patient data access.
Step 8: Create APEX Dashboard for Patient Insights

Build patient 360 dashboard showing demographics, recent notes, imaging thumbnails, and risk scores.
Add filters by demographics, diagnosis codes, and predicted risk.
Expected Outcomes:

Learn to combine JSON, Graph, Vector, and AutoML for healthcare data convergence.
Understand implementation of healthcare compliance using Oracle security features.
Build end-to-end predictive and exploratory healthcare application in ~3.5 hours.



3.4 Manufacturing â€“ Smart Factory and Supply Chain Digital Twin
Lab Objective: Build a digital twin of manufacturing processes and supply chain networks for real-time monitoring and predictive maintenance using Oracle 23ai.

Key Challenges:

Integration of heterogeneous IoT sensor data
Supply chain complexity with multiple stakeholders
Need for predictive analytics to avoid downtime
Oracle 23ai Solutions:

JSON Duality to store IoT sensor data and metadata
Graph to model supply chain and factory process relationships
Vector Search for analyzing sensor time-series and anomaly detection
AutoML for predictive maintenance
ðŸ§ª Guided Tech Do-Along

Lab Duration: ~3 Hours

Step 1: Setup User and Schema

CREATE USER manuflab IDENTIFIED BY Manu123;
GRANT CONNECT, RESOURCE TO manuflab;
ALTER SESSION SET CURRENT_SCHEMA = manuflab;
Step 2: Create Tables for IoT Data & Supply Chain

CREATE TABLE machine (
  machine_id NUMBER PRIMARY KEY,
  metadata JSON
);

CREATE TABLE sensor_data (
  sensor_id NUMBER PRIMARY KEY,
  machine_id NUMBER,
  reading_time TIMESTAMP,
  sensor_readings JSON,
  embedding VECTOR(1536),
  CONSTRAINT fk_machine FOREIGN KEY (machine_id) REFERENCES machine(machine_id)
);

CREATE TABLE supply_chain_partner (
  partner_id NUMBER PRIMARY KEY,
  partner_info JSON
);

CREATE TABLE supply_chain_flow (
  flow_id NUMBER PRIMARY KEY,
  from_partner NUMBER,
  to_partner NUMBER,
  product_id NUMBER,
  CONSTRAINT fk_from FOREIGN KEY (from_partner) REFERENCES supply_chain_partner(partner_id),
  CONSTRAINT fk_to FOREIGN KEY (to_partner) REFERENCES supply_chain_partner(partner_id)
);
Step 3: Load Sensor & Partner Data

Use sample JSON-formatted sensor and partner data from lab repo.
Use SQL*Loader or batch inserts.
Step 4: Create Graph for Factory and Supply Chain

CREATE PROPERTY GRAPH manuf_pg
  VERTEX TABLES (
    machine KEY (machine_id),
    supply_chain_partner KEY (partner_id)
  )
  EDGE TABLES (
    flow FROM supply_chain_flow TO supply_chain_flow
  );
Step 5: Vector Search on Sensor Readings for Anomaly Detection

SELECT sensor_id, sensor_readings
FROM sensor_data
WHERE embedding ANN SENSOR_VECTOR LIMIT 5;
Use vector similarity to detect sensor anomalies or failure patterns.

Step 6: Build AutoML Predictive Maintenance Model

Prepare labeled sensor data indicating failure events.
BEGIN
  DBMS_DATA_MINING.CREATE_MODEL(
    model_name          => 'MAINTENANCE_MODEL',
    mining_function     => DBMS_DATA_MINING.CLASSIFICATION,
    data_table_name     => 'sensor_data',
    case_id_column_name => 'sensor_id',
    target_column_name  => 'failure_flag',
    settings_table_name => 'maint_settings');
END;
Step 7: Build Oracle APEX Monitoring Dashboard

Visualize machine health, sensor anomalies, and supply chain status.
Include alerts triggered by maintenance model predictions.
Expected Outcomes:

Hands-on experience with IoT data management using JSON duality and Vector.
Graph modeling of supply chain partners and flows.
Predictive maintenance insights driven fully in-database.




3.5 Telecommunications â€“ Network Analytics & Customer Experience
Lab Objective: Analyze telecom network topology and customer behavior using converged Oracle 23ai features to improve service and reduce churn.

Key Challenges:

Complex network graphs with many nodes and edges
Real-time analysis of call records and customer interactions
Fraud detection and churn prediction
Oracle 23ai Solutions:

Graph to model telecom network elements and routing
JSON Duality for call detail records and customer metadata
Vector Search for clustering user behavior patterns
AutoML for network anomaly detection and churn prediction
ðŸ§ª Guided Tech Do-Along

Lab Duration: ~3 Hours

Step 1: Setup User and Schema

CREATE USER telecomlab IDENTIFIED BY Telco123;
GRANT CONNECT, RESOURCE TO telecomlab;
ALTER SESSION SET CURRENT_SCHEMA = telecomlab;
Step 2: Create Tables for Network and Call Data

CREATE TABLE network_node (
  node_id NUMBER PRIMARY KEY,
  node_info JSON
);

CREATE TABLE call_records (
  call_id NUMBER PRIMARY KEY,
  caller_id NUMBER,
  callee_id NUMBER,
  call_time TIMESTAMP,
  call_metadata JSON,
  fraud_flag NUMBER
);

CREATE TABLE customer_profile (
  customer_id NUMBER PRIMARY KEY,
  profile_data JSON,
  embedding VECTOR(1536)
);
Step 3: Load Network and Call Data

Use sample JSON datasets of telecom nodes, calls, and customer info.
Step 4: Create Telecom Network Graph

CREATE PROPERTY GRAPH telecom_pg
  VERTEX TABLES (network_node KEY (node_id))
  EDGE TABLES (
    call_edge FROM call_records TO call_records
  );
Step 5: Vector Search for User Behavior Clustering

SELECT customer_id, profile_data
FROM customer_profile
WHERE embedding ANN USER_VECTOR LIMIT 5;
Step 6: Build AutoML Models

Fraud detection model using call_records table.
Churn prediction model using customer_profile data.
BEGIN
  DBMS_DATA_MINING.CREATE_MODEL(
    model_name          => 'FRAUD_DETECTION_MODEL',
    mining_function     => DBMS_DATA_MINING.CLASSIFICATION,
    data_table_name     => 'call_records',
    case_id_column_name => 'call_id',
    target_column_name  => 'fraud_flag',
    settings_table_name => 'fraud_settings');
END;
Step 7: Build Real-Time Monitoring Dashboard in APEX

Visualize network health, flagged calls, and churn risk.
Include filters for geography, time, and customer segment.
Expected Outcomes:

Master telecom network modeling with Graph DB.
Analyze call data with JSON and Vector.
Deploy ML-driven fraud and churn analytics fully in-database.
Launch monitoring dashboards for operational insight.
